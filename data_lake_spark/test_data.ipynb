{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "import os\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "\n",
    "config.read_file(open('/Users/danieldiamond/.aws/credentials'))\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = config.get('sparkifyuser',\n",
    "                                             'AWS_ACCESS_KEY_ID')\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = config.get('sparkifyuser',\n",
    "                                             'AWS_SECRET_ACCESS_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"s3a://udacity-dend\"\n",
    "output_data = \"s3a://sparkify-bucket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                     .config(\"spark.jars.packages\",\n",
    "                             \"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_path = './data/song_data/*/*/*/*.json'\n",
    "song_data = spark.read.json(song_path)\n",
    "song_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_path = './data/log-data/*.json'\n",
    "log_data = spark.read.json(log_path)\n",
    "log_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ts: long (nullable = true)\n",
      " |-- start_time: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_data = log_data.withColumn('start_time', \n",
    "                                F.from_unixtime(F.col('ts')/1000))\n",
    "time_data = time_data.select('ts', 'start_time') \\\n",
    "               .withColumn('year', F.year('start_time')) \\\n",
    "               .withColumn('month', F.month('start_time')) \\\n",
    "               .withColumn('week', F.weekofyear('start_time')) \\\n",
    "               .withColumn('weekday', F.dayofweek('start_time')) \\\n",
    "               .withColumn('day', F.dayofyear('start_time')) \\\n",
    "               .withColumn('hour', F.hour('start_time')).dropDuplicates()\n",
    "time_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data.createOrReplaceTempView('song_data')\n",
    "log_data.createOrReplaceTempView('log_data')\n",
    "time_data.createOrReplaceTempView('time_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays_table = spark.sql(\"\"\"SELECT DISTINCT\n",
    "                                       l.ts as ts,\n",
    "                                       t.year as year,\n",
    "                                       t.month as month,\n",
    "                                       l.userId as user_id,\n",
    "                                       l.level as level,\n",
    "                                       s.song_id as song_id,\n",
    "                                       s.artist_id as artist_id,\n",
    "                                       l.sessionId as session_id,\n",
    "                                       s.artist_location as artist_location,\n",
    "                                       l.userAgent as user_agent\n",
    "                                   FROM song_data s\n",
    "                                   JOIN log_data l\n",
    "                                       ON s.artist_name = l.artist\n",
    "                                       AND s.title = l.song\n",
    "                                       AND s.duration = l.length\n",
    "                                   JOIN time_data t\n",
    "                                       ON t.ts = l.ts\n",
    "                                   \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songplays_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " ts              | 1542837407796        \n",
      " year            | 2018                 \n",
      " month           | 11                   \n",
      " user_id         | 15                   \n",
      " level           | paid                 \n",
      " song_id         | SOZCTXZ12AB0182364   \n",
      " artist_id       | AR5KOSW1187FB35FF4   \n",
      " session_id      | 818                  \n",
      " artist_location | Dubai UAE            \n",
      " user_agent      | \"Mozilla/5.0 (X11... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplays_table.show(1, vertical=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
