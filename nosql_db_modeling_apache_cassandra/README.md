# Project 2: NoSQL Data Modeling with Apache Cassandra

<p align="center"><img src="images/logo.png" style="height: 100%; width: 100%; max-width: 200px" /></p>

## Introduction
As a data engineer, I was responsible for developing a nosql database to empower the analytics team at Sparkify. The analysis team is particularly interested in understanding what songs users are listening to. Currently, there is no easy way to query the data to generate the results, since the data reside in a directory of CSV files on user activity on the app.

### Achievements
Data modeling with Apache Cassandra and building an ETL pipeline using Python. Define table schema based on the analytics team query requirements, and write an ETL pipeline that transfers data from a set of CSV files within a directory to create a streamlined CSV file to model and insert data into Apache Cassandra tables using Python and SQL.
Skills include:
* Building out an ETL pipeline using Python
* Creating a database schema and ETL pipeline for this analysis
* Creating an Apache Cassandra database with denormalized tables designed to optimize queries on event data.
* Define robust Partition Keys, Clustering Columns and Composite Primary Keys.
* Testing the database and ETL pipeline by running queries given to you by the analytics team from Sparkify and comparing results with their expected results.

### Schema for Data Analysis
Process the event_datafile_new.csv dataset to create a denormalized dataset.
